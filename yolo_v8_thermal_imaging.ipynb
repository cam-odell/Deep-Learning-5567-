{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2903151,
          "sourceType": "datasetVersion",
          "datasetId": 786319
        }
      ],
      "dockerImageVersionId": 30527,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCcIvUsOZT3O",
        "outputId": "2afa9e66-076b-417c-979a-702e956d901e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.utils import shuffle\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:41:35.572357Z",
          "iopub.execute_input": "2024-04-24T06:41:35.572918Z",
          "iopub.status.idle": "2024-04-24T06:41:35.581545Z",
          "shell.execute_reply.started": "2024-04-24T06:41:35.572850Z",
          "shell.execute_reply": "2024-04-24T06:41:35.580088Z"
        },
        "trusted": true,
        "id": "NH--_l9dFsBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_class_mapping(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    classes = df['class'].unique()\n",
        "    return {name: idx for idx, name in enumerate(classes)}\n",
        "\n",
        "train_csv = '/content/drive/My Drive/Datasets/Thermal_Images/train_annotations.csv'\n",
        "class_to_id = create_class_mapping(train_csv)\n",
        "print(\"Class to ID mapping:\", class_to_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbU2pg2zpXxK",
        "outputId": "40a224de-34a9-49c3-9324-bacdd46bf5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class to ID mapping: {'person': 0, 'dog': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_annotations(csv_file, image_dir, label_dir, class_to_id, img_width, img_height):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df[df['class'].notna() & df['class'].isin(class_to_id.keys())]\n",
        "    os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        file_name = row['filename']\n",
        "        class_name = row['class']\n",
        "        if class_name not in class_to_id:\n",
        "            print(f\"Skipping unrecognized class: {class_name} in file {file_name}\")\n",
        "            continue\n",
        "\n",
        "        class_id = class_to_id[class_name]\n",
        "        xmin, ymin, xmax, ymax = map(float, [row['xmin'], row['ymin'], row['xmax'], row['ymax']])\n",
        "        x_center = ((xmin + xmax) / 2) / img_width\n",
        "        y_center = ((ymin + ymax) / 2) / img_height\n",
        "        bbox_width = (xmax - xmin) / img_width\n",
        "        bbox_height = (ymax - ymin) / img_height\n",
        "        label_str = f\"{class_id} {x_center} {y_center} {bbox_width} {bbox_height}\\n\"\n",
        "\n",
        "        txt_file_path = os.path.join(label_dir, os.path.splitext(file_name)[0] + '.txt')\n",
        "        with open(txt_file_path, 'a') as file:\n",
        "            file.write(label_str)"
      ],
      "metadata": {
        "id": "seGht3daZhsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_sample_images(csv_file, image_dir, num_samples=5):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    sample_df = df.sample(n=num_samples)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    for index, (i, row) in enumerate(sample_df.iterrows()):\n",
        "        img_path = os.path.join(image_dir, row['filename'])\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            print(f\"Failed to load image: {img_path}\")\n",
        "            continue\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        xmin, ymin, xmax, ymax = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
        "\n",
        "        plt.subplot(num_samples, 1, index + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.gca().add_patch(Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=1, edgecolor='red', facecolor='none'))\n",
        "        plt.title(f\"Class: {row['class']}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "bgDxO2cOTv8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height = 416, 416\n",
        "\n",
        "\n",
        "datasets = {\n",
        "    \"train\": ('train_annotations.csv', 'train', 'train_labels'),\n",
        "    \"test\": ('test_annotations.csv', 'test', 'test_labels'),\n",
        "    \"valid\": ('valid_annotations.csv', 'valid', 'valid_labels')\n",
        "}\n",
        "\n",
        "for dataset_type, paths in datasets.items():\n",
        "    csv_file, images_dir, labels_dir = [os.path.join('/content/drive/My Drive/Datasets/Thermal_Images', path) for path in paths]\n",
        "    process_annotations(csv_file, images_dir, labels_dir, class_to_id, img_width, img_height)\n",
        "\n",
        "\n",
        "display_sample_images(train_csv, '/content/drive/My Drive/Datasets/Thermal_Images/train')"
      ],
      "metadata": {
        "id": "v7D1l6j8TzdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-04-24T06:41:38.245130Z",
          "iopub.execute_input": "2024-04-24T06:41:38.245584Z",
          "iopub.status.idle": "2024-04-24T06:41:55.608760Z",
          "shell.execute_reply.started": "2024-04-24T06:41:38.245545Z",
          "shell.execute_reply": "2024-04-24T06:41:55.607121Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVtuUMKewzPR",
        "outputId": "c9197149-fca3-4592-fd13-41a7c9edfc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.14)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQMs2Xdm6YLz",
        "outputId": "07d2ee2e-3b58-4b1a-f7b7-d17ddb784456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "data = {\n",
        "    'path': '/content/drive/My Drive/Datasets/Thermal_Images',\n",
        "    'train': 'train',\n",
        "    'val': 'valid',\n",
        "    'test': 'test',\n",
        "\n",
        "\n",
        "    'train_labels': 'train_labels',\n",
        "    'val_labels': 'valid_labels',\n",
        "    'test_labels': 'test_labels',\n",
        "\n",
        "    'nc': 2,\n",
        "    'names': ['Dog', 'Human']\n",
        "}\n",
        "\n",
        "yaml_path = '/content/drive/My Drive/Datasets/Thermal_Images/dataset.yaml'\n",
        "\n",
        "with open(yaml_path, 'w') as file:\n",
        "    yaml.dump(data, file, sort_keys=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "1bLHClDJ6fhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "id": "zgxivWFsw2Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8m.pt\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:41:59.266439Z",
          "iopub.execute_input": "2024-04-24T06:41:59.267237Z",
          "iopub.status.idle": "2024-04-24T06:42:00.213735Z",
          "shell.execute_reply.started": "2024-04-24T06:41:59.267197Z",
          "shell.execute_reply": "2024-04-24T06:42:00.212389Z"
        },
        "trusted": true,
        "id": "XDBjiTcDw5LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO  # Make sure this import works with your setup\n",
        "\n",
        "def train_yolo_model():\n",
        "    # Initialize the model (ensure the model weights path and YOLO version are correct)\n",
        "    model = YOLO('yolov8m.pt')  # Adjust the path to pre-trained weights if needed\n",
        "\n",
        "    # Start training the model\n",
        "    model.train(\n",
        "        data=yaml_path,  # Use the YAML file path created above\n",
        "        epochs=50,       # Define the number of training epochs\n",
        "        batch=16,        # Define the batch size\n",
        "        imgsz=416,       # Standard image size for YOLO is usually 416x416 or 640x640\n",
        "        device='0',      # GPU device (CUDA) if available, otherwise 'cpu'\n",
        "        cache=True       # Caching images to RAM for faster training if RAM allows\n",
        "    )\n",
        "\n",
        "# Call the function to start training\n",
        "train_yolo_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dnYKG3tO60S2",
        "outputId": "d1f9040b-6729-4141-daf4-f6991d8d8ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.14 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/drive/My Drive/Datasets/Thermal_Images/dataset.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=True, device=0, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train11\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n",
            "Model summary: 295 layers, 25857478 parameters, 25857462 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train11', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/My Drive/Datasets/Thermal_Images/train.cache... 0 images, 142 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ No labels found in /content/drive/My Drive/Datasets/Thermal_Images/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:00<00:00, 358.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/Datasets/Thermal_Images/valid.cache... 0 images, 41 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ No labels found in /content/drive/My Drive/Datasets/Thermal_Images/valid.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 298.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train11/labels.jpg... \n",
            "zero-size array to reduction operation maximum which has no identity\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 416 train, 416 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train11\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      4.67G          0        121          0          0        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         41          0          0          0          0          0\n",
            "WARNING âš ï¸ no labels found in detect set, can not compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      3.84G          0      104.6          0          0        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         41          0          0          0          0          0\n",
            "WARNING âš ï¸ no labels found in detect set, can not compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      4.12G          0      40.52          0          0        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         41          0          0          0          0          0\n",
            "WARNING âš ï¸ no labels found in detect set, can not compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50         4G          0      23.74          0          0        416:  11%|â–ˆ         | 1/9 [00:00<00:01,  5.14it/s]Exception in thread Thread-335 (_pin_memory_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 53, in _pin_memory_loop\n",
            "    do_one_step()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 30, in do_one_step\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
            "    c = SocketClient(address)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "       4/50         4G          0      23.74          0          0        416:  11%|â–ˆ         | 1/9 [00:00<00:03,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-dcbf894c7227>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Call the function to start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain_yolo_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-111-dcbf894c7227>\u001b[0m in \u001b[0;36mtrain_yolo_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Start training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     model.train(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml_path\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Use the YAML file path created above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0;31m# Define the number of training epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;31m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def verify_labels(base_path, image_folder, label_folder):\n",
        "    label_dir = os.path.join(base_path, label_folder)\n",
        "    image_dir = os.path.join(base_path, image_folder)\n",
        "\n",
        "    labels = os.listdir(label_dir)\n",
        "    images = os.listdir(image_dir)\n",
        "\n",
        "    print(f\"Total labels: {len(labels)}, Total images: {len(images)}\")\n",
        "\n",
        "    # Check for matching image files for label files\n",
        "    for label_file in labels[:5]:  # Check the first 5 label files\n",
        "        image_file = label_file.replace('.txt', '.jpg')  # Adjust the extension if your images are in a different format\n",
        "        image_path = os.path.join(image_dir, image_file)\n",
        "        label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "        if os.path.exists(image_path):\n",
        "            print(f\"Matching image for {label_file} exists.\")\n",
        "        else:\n",
        "            print(f\"No matching image for {label_file}.\")\n",
        "\n",
        "        with open(label_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "            if not lines:\n",
        "                print(f\"{label_file} is empty.\")\n",
        "            else:\n",
        "                print(f\"{label_file} contains: {lines}\")\n",
        "\n",
        "base_path = '/content/drive/My Drive/Datasets/Thermal_Images'\n",
        "verify_labels(base_path, 'train', 'train_labels')  # Adjust as needed for 'valid'/'valid_labels' or 'test'/'test_labels'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNMnHcf7bYH8",
        "outputId": "323d368c-ac69-4c86-8445-a8e7f7cad1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total labels: 131, Total images: 142\n",
            "Matching image for IMG_0112_jpg.rf.016d04c2af3bc0221a5153d6af8b9f30.txt exists.\n",
            "IMG_0112_jpg.rf.016d04c2af3bc0221a5153d6af8b9f30.txt contains: ['0 0.7127403846153846 0.6213942307692307 0.04567307692307692 0.06490384615384616\\n', '0 0.7127403846153846 0.6213942307692307 0.04567307692307692 0.06490384615384616\\n', '0 0.7127403846153846 0.6213942307692307 0.04567307692307692 0.06490384615384616\\n', '0 0.7127403846153846 0.6213942307692307 0.04567307692307692 0.06490384615384616\\n']\n",
            "Matching image for IMG_0054_jpg.rf.03e0fd11bad6afeb085f2f156d7fd043.txt exists.\n",
            "IMG_0054_jpg.rf.03e0fd11bad6afeb085f2f156d7fd043.txt contains: ['1 0.4338942307692308 0.546875 0.7139423076923077 0.8677884615384616\\n', '1 0.4338942307692308 0.546875 0.7139423076923077 0.8677884615384616\\n', '1 0.4338942307692308 0.546875 0.7139423076923077 0.8677884615384616\\n', '1 0.4338942307692308 0.546875 0.7139423076923077 0.8677884615384616\\n']\n",
            "Matching image for IMG_0094_jpg.rf.03dbd175cdbd5379608debcc783a5361.txt exists.\n",
            "IMG_0094_jpg.rf.03dbd175cdbd5379608debcc783a5361.txt contains: ['0 0.6454326923076923 0.5444711538461539 0.06490384615384616 0.0985576923076923\\n', '0 0.5949519230769231 0.5504807692307693 0.05048076923076923 0.09615384615384616\\n', '0 0.6454326923076923 0.5444711538461539 0.06490384615384616 0.0985576923076923\\n', '0 0.5949519230769231 0.5504807692307693 0.05048076923076923 0.09615384615384616\\n', '0 0.6454326923076923 0.5444711538461539 0.06490384615384616 0.0985576923076923\\n', '0 0.5949519230769231 0.5504807692307693 0.05048076923076923 0.09615384615384616\\n', '0 0.6454326923076923 0.5444711538461539 0.06490384615384616 0.0985576923076923\\n', '0 0.5949519230769231 0.5504807692307693 0.05048076923076923 0.09615384615384616\\n']\n",
            "Matching image for IMG_0109_jpg.rf.03607def018d49330ebef9a856f65812.txt exists.\n",
            "IMG_0109_jpg.rf.03607def018d49330ebef9a856f65812.txt contains: ['0 0.46634615384615385 0.5480769230769231 0.8653846153846154 0.8990384615384616\\n', '0 0.46634615384615385 0.5480769230769231 0.8653846153846154 0.8990384615384616\\n', '0 0.46634615384615385 0.5480769230769231 0.8653846153846154 0.8990384615384616\\n', '0 0.46634615384615385 0.5480769230769231 0.8653846153846154 0.8990384615384616\\n']\n",
            "Matching image for IMG_0056_jpg.rf.0255dca8946ea0a34592394acd67b11b.txt exists.\n",
            "IMG_0056_jpg.rf.0255dca8946ea0a34592394acd67b11b.txt contains: ['1 0.43509615384615385 0.5685096153846154 0.6826923076923077 0.8293269230769231\\n', '1 0.43509615384615385 0.5685096153846154 0.6826923076923077 0.8293269230769231\\n', '1 0.43509615384615385 0.5685096153846154 0.6826923076923077 0.8293269230769231\\n', '1 0.43509615384615385 0.5685096153846154 0.6826923076923077 0.8293269230769231\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def find_missing_labels(image_dir, label_dir):\n",
        "    # List all images and label files\n",
        "    images = {file.split('.')[0] for file in os.listdir(image_dir) if file.endswith('.jpg')}  # Adjust if different image format\n",
        "    labels = {file.split('.')[0] for file in os.listdir(label_dir) if file.endswith('.txt')}\n",
        "\n",
        "    # Find images without corresponding label files\n",
        "    missing_labels = images - labels\n",
        "    print(f\"Images without labels: {len(missing_labels)}\")\n",
        "    for img in missing_labels:\n",
        "        print(img)\n",
        "\n",
        "base_path = '/content/drive/My Drive/Datasets/Thermal_Images'\n",
        "image_dir = os.path.join(base_path, 'train')\n",
        "label_dir = os.path.join(base_path, 'train_labels')\n",
        "find_missing_labels(image_dir, label_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7hWmPojc2jN",
        "outputId": "5f88de4b-72dd-4fb3-df51-57cfb6314efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images without labels: 11\n",
            "IMG_0001_jpg\n",
            "IMG_0019 3_jpg\n",
            "IMG_0001 4_jpg\n",
            "IMG_0008 3_jpg\n",
            "IMG_0021 3_jpg\n",
            "IMG_0020 3_jpg\n",
            "IMG_0005_jpg\n",
            "IMG_0007 4_jpg\n",
            "IMG_0055 2_jpg\n",
            "IMG_0004_jpg\n",
            "IMG_0054 2_jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_empty_labels(image_dir, label_dir):\n",
        "    images = {file.split('.')[0]: file for file in os.listdir(image_dir) if file.endswith('.jpg')}  # Adjust if different image format\n",
        "    labels = {file.split('.')[0] for file in os.listdir(label_dir) if file.endswith('.txt')}\n",
        "\n",
        "    missing_labels = set(images.keys()) - labels\n",
        "    for img in missing_labels:\n",
        "        empty_label_path = os.path.join(label_dir, f\"{img}.txt\")\n",
        "        open(empty_label_path, 'a').close()  # Creates an empty txt file\n",
        "        print(f\"Created empty label for {img}\")\n",
        "\n",
        "create_empty_labels(image_dir, label_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQw83Thec8Jx",
        "outputId": "2821be01-3c99-4cfc-f52d-abe3ebea8c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created empty label for IMG_0001_jpg\n",
            "Created empty label for IMG_0019 3_jpg\n",
            "Created empty label for IMG_0001 4_jpg\n",
            "Created empty label for IMG_0008 3_jpg\n",
            "Created empty label for IMG_0021 3_jpg\n",
            "Created empty label for IMG_0020 3_jpg\n",
            "Created empty label for IMG_0005_jpg\n",
            "Created empty label for IMG_0007 4_jpg\n",
            "Created empty label for IMG_0055 2_jpg\n",
            "Created empty label for IMG_0004_jpg\n",
            "Created empty label for IMG_0054 2_jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_labels_path = '/content/drive/My Drive/Datasets/Thermal_Images/train_labels/'\n",
        "files = os.listdir(train_labels_path)\n",
        "\n",
        "# Check the first 5 label files\n",
        "for file in files[:5]:\n",
        "    full_path = os.path.join(train_labels_path, file)\n",
        "    with open(full_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        print(f\"Contents of {file}: {lines}\")  # Shows the content of label files\n",
        "        if not lines:\n",
        "            print(f\"Warning: {file} is empty.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3xzaLlXWymv",
        "outputId": "7c695e41-3444-4f5f-f4a5-87b8dd3764da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of IMG_0112_jpg.rf.016d04c2af3bc0221a5153d6af8b9f30.txt: ['0 0.7127403846153846 0.6213942307692307 0.04567307692307692 0.06490384615384616\\n', '0 0.7127403846153846 0.6213942307692307 0.04567307692307692 0.06490384615384616\\n', '0 0.7127403846153846 0.6213942307692307 0.04567307692307692 0.06490384615384616\\n', '0 0.7127403846153846 0.6213942307692307 0.04567307692307692 0.06490384615384616\\n']\n",
            "Contents of IMG_0054_jpg.rf.03e0fd11bad6afeb085f2f156d7fd043.txt: ['1 0.4338942307692308 0.546875 0.7139423076923077 0.8677884615384616\\n', '1 0.4338942307692308 0.546875 0.7139423076923077 0.8677884615384616\\n', '1 0.4338942307692308 0.546875 0.7139423076923077 0.8677884615384616\\n', '1 0.4338942307692308 0.546875 0.7139423076923077 0.8677884615384616\\n']\n",
            "Contents of IMG_0094_jpg.rf.03dbd175cdbd5379608debcc783a5361.txt: ['0 0.6454326923076923 0.5444711538461539 0.06490384615384616 0.0985576923076923\\n', '0 0.5949519230769231 0.5504807692307693 0.05048076923076923 0.09615384615384616\\n', '0 0.6454326923076923 0.5444711538461539 0.06490384615384616 0.0985576923076923\\n', '0 0.5949519230769231 0.5504807692307693 0.05048076923076923 0.09615384615384616\\n', '0 0.6454326923076923 0.5444711538461539 0.06490384615384616 0.0985576923076923\\n', '0 0.5949519230769231 0.5504807692307693 0.05048076923076923 0.09615384615384616\\n', '0 0.6454326923076923 0.5444711538461539 0.06490384615384616 0.0985576923076923\\n', '0 0.5949519230769231 0.5504807692307693 0.05048076923076923 0.09615384615384616\\n']\n",
            "Contents of IMG_0109_jpg.rf.03607def018d49330ebef9a856f65812.txt: ['0 0.46634615384615385 0.5480769230769231 0.8653846153846154 0.8990384615384616\\n', '0 0.46634615384615385 0.5480769230769231 0.8653846153846154 0.8990384615384616\\n', '0 0.46634615384615385 0.5480769230769231 0.8653846153846154 0.8990384615384616\\n', '0 0.46634615384615385 0.5480769230769231 0.8653846153846154 0.8990384615384616\\n']\n",
            "Contents of IMG_0056_jpg.rf.0255dca8946ea0a34592394acd67b11b.txt: ['1 0.43509615384615385 0.5685096153846154 0.6826923076923077 0.8293269230769231\\n', '1 0.43509615384615385 0.5685096153846154 0.6826923076923077 0.8293269230769231\\n', '1 0.43509615384615385 0.5685096153846154 0.6826923076923077 0.8293269230769231\\n', '1 0.43509615384615385 0.5685096153846154 0.6826923076923077 0.8293269230769231\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display detection results\n",
        "def display_detections(model, image_dir):\n",
        "\n",
        "    images = [img for img in os.listdir(image_dir) if img.endswith('.jpg')]\n",
        "    random_image_name = random.choice(images)\n",
        "    image_path = os.path.join(image_dir, random_image_name)\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Display the image\n",
        "    results = model.predict(source=image_path, save=False, conf=0.25, iou=0.45)\n",
        "\n",
        "    print(results)  # Debug: print results to see the structure\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # Assuming results.pandas().xyxy[0] works for accessing bounding boxes\n",
        "    if hasattr(results, 'pandas'):\n",
        "        bbox_data = results.pandas().xyxy[0]  # Using .pandas() if applicable\n",
        "    else:\n",
        "        bbox_data = results  # Fallback if no .pandas() method\n",
        "\n",
        "    # Draw bounding boxes and labels\n",
        "    for index, row in bbox_data.iterrows():\n",
        "        x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
        "        rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x1, y1, f'{row[\"name\"]} {row[\"confidence\"]:.2f}', color='white', fontsize=8, backgroundcolor='red')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage: display a random image from the training dataset\n",
        "display_detections(model, train_images_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yfR5wSEwzaXB",
        "outputId": "cc44202a-637a-415c-8adf-8cf12a3283a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/My Drive/Datasets/PlantDoc Dataset/train/22+August+2013+010-1_jpg.rf.63a6322b8174b0ae85c42d43a9603406.jpg: 640x640 (no detections), 37.7ms\n",
            "Speed: 2.8ms preprocess, 37.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "[ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
            "obb: None\n",
            "orig_img: array([[[248, 249, 245],\n",
            "        [255, 255, 252],\n",
            "        [255, 255, 252],\n",
            "        ...,\n",
            "        [174, 228, 191],\n",
            "        [200, 238, 202],\n",
            "        [217, 249, 214]],\n",
            "\n",
            "       [[255, 255, 252],\n",
            "        [255, 255, 252],\n",
            "        [248, 249, 245],\n",
            "        ...,\n",
            "        [162, 209, 171],\n",
            "        [207, 240, 203],\n",
            "        [214, 240, 204]],\n",
            "\n",
            "       [[254, 255, 251],\n",
            "        [255, 255, 252],\n",
            "        [255, 255, 252],\n",
            "        ...,\n",
            "        [181, 212, 173],\n",
            "        [206, 224, 187],\n",
            "        [221, 233, 197]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[  5,  13,   6],\n",
            "        [  3,  14,   4],\n",
            "        [  0,   7,   0],\n",
            "        ...,\n",
            "        [ 64, 102, 102],\n",
            "        [ 65, 101, 101],\n",
            "        [ 72, 108, 108]],\n",
            "\n",
            "       [[  4,  12,   5],\n",
            "        [  5,  16,   6],\n",
            "        [  0,   9,   0],\n",
            "        ...,\n",
            "        [  0,  26,  29],\n",
            "        [  5,  38,  41],\n",
            "        [ 16,  49,  52]],\n",
            "\n",
            "       [[  5,  13,   6],\n",
            "        [  7,  18,   8],\n",
            "        [  4,  15,   5],\n",
            "        ...,\n",
            "        [ 40,  75,  78],\n",
            "        [ 20,  53,  56],\n",
            "        [  3,  36,  39]]], dtype=uint8)\n",
            "orig_shape: (100, 100)\n",
            "path: '/content/drive/My Drive/Datasets/PlantDoc Dataset/train/22+August+2013+010-1_jpg.rf.63a6322b8174b0ae85c42d43a9603406.jpg'\n",
            "probs: None\n",
            "save_dir: 'runs/detect/predict'\n",
            "speed: {'preprocess': 2.8295516967773438, 'inference': 37.67681121826172, 'postprocess': 0.8053779602050781}]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'iterrows'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-c75192c490be>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Example usage: display a random image from the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mdisplay_detections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-c75192c490be>\u001b[0m in \u001b[0;36mdisplay_detections\u001b[0;34m(model, image_dir)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Draw bounding boxes and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbbox_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xmin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ymin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xmax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ymax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'iterrows'"
          ]
        }
      ]
    }
  ]
}