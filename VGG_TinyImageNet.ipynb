{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NV85y_deaQW",
        "outputId": "d696521f-60a5-4950-a7eb-abc2fdd7be47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IMagenet'...\n",
            "remote: Enumerating objects: 120594, done.\u001b[K\n",
            "remote: Total 120594 (delta 0), reused 0 (delta 0), pack-reused 120594\u001b[K\n",
            "Receiving objects: 100% (120594/120594), 212.68 MiB | 22.63 MiB/s, done.\n",
            "Resolving deltas: 100% (1115/1115), done.\n",
            "Updating files: 100% (120206/120206), done.\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import imageio\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open(path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.strip()] = i\n",
        "    return id_dict\n",
        "\n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open(path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word.strip()\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])\n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        for i in range(500):\n",
        "            img_path = f'{path}train/{key}/images/{key}_{i}.JPEG'\n",
        "            img = imageio.imread(img_path)\n",
        "            if img.shape != (64, 64, 3):\n",
        "                continue\n",
        "            train_data.append(img)\n",
        "            train_labels.append(value)\n",
        "\n",
        "    for line in open(f'{path}val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        img = imageio.imread(f'{path}val/images/{img_name}')\n",
        "        if img.shape != (64, 64, 3):\n",
        "            continue\n",
        "        test_data.append(img)\n",
        "        test_labels.append(id_dict[class_id])\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data), to_categorical(train_labels, 200), np.array(test_data), to_categorical(test_labels, 200)\n",
        "\n",
        "class_to_id = get_class_to_id_dict()\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())\n",
        "print(\"train data shape: \", train_data.shape)\n",
        "print(\"train label shape: \", train_labels.shape)\n",
        "print(\"test data shape: \", test_data.shape)\n",
        "print(\"test_labels.shape: \", test_labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHxLHHQphQN2",
        "outputId": "a14d8652-4a3a-462f-94f9-e0952683bcc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting loading data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2f3a657d405e>:33: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  img = imageio.imread(img_path)\n",
            "<ipython-input-2-2f3a657d405e>:41: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  img = imageio.imread(f'{path}val/images/{img_name}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished loading data, in 43.862701416015625 seconds\n",
            "train data shape:  (98179, 64, 64, 3)\n",
            "train label shape:  (98179, 200)\n",
            "test data shape:  (9832, 64, 64, 3)\n",
            "test_labels.shape:  (9832, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_data(train_data, train_labels ):\n",
        "    size = len(train_data)\n",
        "    train_idx = np.arange(size)\n",
        "    np.random.shuffle(train_idx)\n",
        "\n",
        "    return train_data[train_idx], train_labels[train_idx]\n",
        "\n",
        "train_data, train_labels = shuffle_data(train_data, train_labels)"
      ],
      "metadata": {
        "id": "1l3iqQq6hSrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
      ],
      "metadata": {
        "id": "XTEhzF4snCKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(200, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "0bQs-ZIWnLku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow(train_data, train_labels, batch_size=32)\n",
        "val_generator = val_datagen.flow(test_data, test_labels, batch_size=32)\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)"
      ],
      "metadata": {
        "id": "AWXIpMrznPVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HphdePndoeFd",
        "outputId": "f3ce52da-7f03-40f2-844c-29f369de75bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 512)               0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 200)               102600    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20389640 (77.78 MB)\n",
            "Trainable params: 7444680 (28.40 MB)\n",
            "Non-trainable params: 12944960 (49.38 MB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_data) // 32,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(test_data) // 32,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyxnyuRTnSdx",
        "outputId": "7d92c51f-041d-42ba-dd28-85161e14d6c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "3068/3068 [==============================] - 121s 39ms/step - loss: 1.5850 - accuracy: 0.6082 - val_loss: 2.4957 - val_accuracy: 0.5024\n",
            "Epoch 2/30\n",
            "3068/3068 [==============================] - 121s 39ms/step - loss: 1.5703 - accuracy: 0.6117 - val_loss: 2.5216 - val_accuracy: 0.5029\n",
            "Epoch 3/30\n",
            "3068/3068 [==============================] - 125s 41ms/step - loss: 1.5472 - accuracy: 0.6176 - val_loss: 2.4921 - val_accuracy: 0.5060\n",
            "Epoch 4/30\n",
            "3068/3068 [==============================] - 124s 40ms/step - loss: 1.5333 - accuracy: 0.6202 - val_loss: 2.4893 - val_accuracy: 0.5077\n",
            "Epoch 5/30\n",
            "3068/3068 [==============================] - 123s 40ms/step - loss: 1.5114 - accuracy: 0.6266 - val_loss: 2.5727 - val_accuracy: 0.5062\n",
            "Epoch 6/30\n",
            "3068/3068 [==============================] - 126s 41ms/step - loss: 1.5049 - accuracy: 0.6273 - val_loss: 2.4994 - val_accuracy: 0.5130\n",
            "Epoch 7/30\n",
            "3068/3068 [==============================] - 126s 41ms/step - loss: 1.4908 - accuracy: 0.6314 - val_loss: 2.6518 - val_accuracy: 0.5072\n",
            "Epoch 8/30\n",
            "3068/3068 [==============================] - 125s 41ms/step - loss: 1.4808 - accuracy: 0.6335 - val_loss: 2.6675 - val_accuracy: 0.5046\n",
            "Epoch 9/30\n",
            "3068/3068 [==============================] - 125s 41ms/step - loss: 1.4569 - accuracy: 0.6386 - val_loss: 2.7011 - val_accuracy: 0.5054\n",
            "Epoch 10/30\n",
            "3068/3068 [==============================] - 123s 40ms/step - loss: 1.4462 - accuracy: 0.6409 - val_loss: 2.7419 - val_accuracy: 0.5068\n",
            "Epoch 11/30\n",
            "3068/3068 [==============================] - 124s 40ms/step - loss: 1.4421 - accuracy: 0.6434 - val_loss: 2.6238 - val_accuracy: 0.5029\n"
          ]
        }
      ]
    }
  ]
}