{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.applications import VGG19\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from keras.datasets import cifar100\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import cv2\n"
      ],
      "metadata": {
        "id": "OrtL_jJVE4TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_val, y_val) = cifar100.load_data()\n",
        "\n",
        "# One-hot encoding\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_val = to_categorical(y_val, 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xI_CNJ6U87j",
        "outputId": "98cbf739-e2ba-45c4-d1d1-bcf6789e2bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19_model = VGG19(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(vgg19_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# freeze\n",
        "vgg19_model.trainable = False\n"
      ],
      "metadata": {
        "id": "zqvtZ5zoVA0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
        "\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=lambda x: cv2.resize(x, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
        ")\n",
        "\n",
        "train_iterator = datagen.flow(x_train, y_train, batch_size=128)\n",
        "val_iterator = datagen.flow(x_val, y_val, batch_size=128)"
      ],
      "metadata": {
        "id": "4I_FOuS9U3O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    min_delta=0.001,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_iterator,\n",
        "    epochs=30,\n",
        "    validation_data=val_iterator,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ADtnxicYJPi",
        "outputId": "97bded2a-22e0-46f5-c272-5ff7df75eba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "391/391 [==============================] - 10s 24ms/step - loss: 3.6104 - categorical_accuracy: 0.1596 - val_loss: 3.0912 - val_categorical_accuracy: 0.2549\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 3.1032 - categorical_accuracy: 0.2395 - val_loss: 2.8969 - val_categorical_accuracy: 0.2849\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.9461 - categorical_accuracy: 0.2703 - val_loss: 2.8137 - val_categorical_accuracy: 0.3064\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.8536 - categorical_accuracy: 0.2898 - val_loss: 2.7600 - val_categorical_accuracy: 0.3081\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 2.7818 - categorical_accuracy: 0.3042 - val_loss: 2.7108 - val_categorical_accuracy: 0.3199\n",
            "Epoch 6/30\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 2.7264 - categorical_accuracy: 0.3135 - val_loss: 2.6783 - val_categorical_accuracy: 0.3275\n",
            "Epoch 7/30\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 2.6779 - categorical_accuracy: 0.3219 - val_loss: 2.6609 - val_categorical_accuracy: 0.3340\n",
            "Epoch 8/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.6359 - categorical_accuracy: 0.3297 - val_loss: 2.6398 - val_categorical_accuracy: 0.3370\n",
            "Epoch 9/30\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 2.6069 - categorical_accuracy: 0.3353 - val_loss: 2.6175 - val_categorical_accuracy: 0.3410\n",
            "Epoch 10/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.5703 - categorical_accuracy: 0.3415 - val_loss: 2.6038 - val_categorical_accuracy: 0.3457\n",
            "Epoch 11/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.5444 - categorical_accuracy: 0.3470 - val_loss: 2.6042 - val_categorical_accuracy: 0.3427\n",
            "Epoch 12/30\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 2.5083 - categorical_accuracy: 0.3545 - val_loss: 2.5827 - val_categorical_accuracy: 0.3440\n",
            "Epoch 13/30\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 2.4863 - categorical_accuracy: 0.3589 - val_loss: 2.5752 - val_categorical_accuracy: 0.3497\n",
            "Epoch 14/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.4530 - categorical_accuracy: 0.3684 - val_loss: 2.5673 - val_categorical_accuracy: 0.3501\n",
            "Epoch 15/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.4343 - categorical_accuracy: 0.3727 - val_loss: 2.5565 - val_categorical_accuracy: 0.3501\n",
            "Epoch 16/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.4081 - categorical_accuracy: 0.3750 - val_loss: 2.5576 - val_categorical_accuracy: 0.3548\n",
            "Epoch 17/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.3904 - categorical_accuracy: 0.3786 - val_loss: 2.5540 - val_categorical_accuracy: 0.3537\n",
            "Epoch 18/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.3638 - categorical_accuracy: 0.3827 - val_loss: 2.5507 - val_categorical_accuracy: 0.3545\n",
            "Epoch 19/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.3428 - categorical_accuracy: 0.3898 - val_loss: 2.5512 - val_categorical_accuracy: 0.3567\n",
            "Epoch 20/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.3284 - categorical_accuracy: 0.3887 - val_loss: 2.5482 - val_categorical_accuracy: 0.3575\n",
            "Epoch 21/30\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 2.3047 - categorical_accuracy: 0.3956 - val_loss: 2.5436 - val_categorical_accuracy: 0.3619\n",
            "Epoch 22/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.2857 - categorical_accuracy: 0.4018 - val_loss: 2.5418 - val_categorical_accuracy: 0.3616\n",
            "Epoch 23/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.2688 - categorical_accuracy: 0.4059 - val_loss: 2.5541 - val_categorical_accuracy: 0.3575\n",
            "Epoch 24/30\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 2.2516 - categorical_accuracy: 0.4080 - val_loss: 2.5430 - val_categorical_accuracy: 0.3592\n",
            "Epoch 25/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.2247 - categorical_accuracy: 0.4120 - val_loss: 2.5474 - val_categorical_accuracy: 0.3619\n",
            "Epoch 26/30\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 2.2232 - categorical_accuracy: 0.4143 - val_loss: 2.5457 - val_categorical_accuracy: 0.3631\n",
            "Epoch 27/30\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2020 - categorical_accuracy: 0.4164Restoring model weights from the end of the best epoch: 22.\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 2.2020 - categorical_accuracy: 0.4164 - val_loss: 2.5517 - val_categorical_accuracy: 0.3630\n",
            "Epoch 27: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f62e4436110>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}